{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect Google Drive (GDrive) with Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4218,
     "status": "ok",
     "timestamp": 1639892969938,
     "user": {
      "displayName": "Hemanth Kumar A",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11979624875839554361"
     },
     "user_tz": -330
    },
    "id": "M41WPxRP93BG",
    "outputId": "36086378-44d9-4a4d-a22a-e58d3d53494c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1639831995678,
     "user": {
      "displayName": "Kalpana Kadirvel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09418559652146925726"
     },
     "user_tz": -330
    },
    "id": "FH1-0nEf-loV",
    "outputId": "f85ee285-9c71-4bde-bb83-010f4f6e7592"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/dogs-vs-cats.zip\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-TqQjxNHCPL"
   },
   "source": [
    "**Extracting the data**\n",
    "\n",
    "- unzip the zip file on google colab and save it in a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "error",
     "timestamp": 1639892975186,
     "user": {
      "displayName": "Hemanth Kumar A",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11979624875839554361"
     },
     "user_tz": -330
    },
    "id": "BjSPrikSB6DO",
    "outputId": "cc4dbb0f-9e3d-4157-dc2f-c48e83d7ecbc"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"/content/train.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"/content/drive/MyDrive/cats_dogs_images\") \n",
    "    # creates new folder 'cats_dogs_images' and saves all images present in train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCPQUKbuG_Fm"
   },
   "source": [
    "**Copying images to training, validation, and test directories**\n",
    "\n",
    "create subset for train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "error",
     "timestamp": 1639832124767,
     "user": {
      "displayName": "Kalpana Kadirvel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09418559652146925726"
     },
     "user_tz": -330
    },
    "id": "nS20ZGOICb-C",
    "outputId": "1ee128b9-7698-4fb4-cbd9-141f9b3bd1d5"
   },
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"/content/drive/MyDrive/cats_dogs_images/train\")\n",
    "new_base_dir = pathlib.Path(\"/content/drive/MyDrive/cats_dogs_images/image_seggrated\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir)\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname,\n",
    "                            dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ipkglw9NHTfa"
   },
   "source": [
    "Building the model: \n",
    "Instantiating a small convnet for dogs vs. cats classification  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential and Functional are two ways to build Keras models. Sequential model is simplest type of model, a linear stock of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "keras.Model():In Functional model, part or all of the inputs directly connected to the output layer. This architecture makes it possible for the neural network to learn both deep patterns and simple rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZtXaFkEEhiY"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ8t6Y44E5hS",
    "outputId": "cddc4579-4a81-4e88-f45a-ee04b7f75ea7"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTx4yTy2HjiC"
   },
   "source": [
    "Configuring the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfsIUVCMFFra"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Yu2fhGFHpYk"
   },
   "source": [
    "Data preprocessing\n",
    "Using image_dataset_from_directory to read images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_dataset_from_directory - yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 1054,
     "status": "error",
     "timestamp": 1639832151702,
     "user": {
      "displayName": "Kalpana Kadirvel",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09418559652146925726"
     },
     "user_tz": -330
    },
    "id": "dtwyDe2QFJ-6",
    "outputId": "d89251d3-0a1c-4e2d-bd67-530ecaad129b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_alTM9HH5TB"
   },
   "source": [
    "Fitting the model using a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callback to save the Keras model or model weights at some frequency. ModelCheckpoint callback is used in conjunction with training using model.fit () to save a model or weights (in a checkpoint file) at some interval, so the model or weights can be loaded later to continue the training from the state saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlWLXZr2F1Dy",
    "outputId": "4ca65bb5-8307-4dff-e2e6-1ee7018775f1"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"convnet_from_scratch.keras\", # path to save the model file\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tm37_1-lH8cx"
   },
   "source": [
    "Displaying curves of loss and accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Ky1YNMZ6GgOa",
    "outputId": "d88d54f3-0ab1-4eb3-b1d6-fc06892fb90d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnKdypoRH_i5"
   },
   "source": [
    "Evaluating the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EyCal9nGqid",
    "outputId": "301f244b-1918-436b-d6de-0c7ccb1a272d"
   },
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n",
    "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cats_vs_dogs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
